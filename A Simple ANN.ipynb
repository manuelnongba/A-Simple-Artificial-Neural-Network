{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdeeb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad61c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(([0,0,0],[0,0,1],[0,1,0], \\\n",
    "             [0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb24345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(([1],[0],[0],[0], \\\n",
    "             [0],[0], [0], [1]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a41821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xPredicted = np.array(([0,0,1]), dtype=float)\n",
    "X = X/np.amax(X,axis= 0)\n",
    "Xpredicted = xPredicted/np.amax(xPredicted, axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05a40bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfile = open(\"SumSquaredLossList.csv\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c1bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        self.inputLayerSize = 3\n",
    "        self.outputLayerSIze = 1\n",
    "        self.hiddenLayerSize = 4\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSIze)\n",
    "        \n",
    "    def feedforward(self, X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.activationSigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        o = self.activationSigmoid(self.z3)\n",
    "        return o\n",
    "    \n",
    "    def backwardPropagate(self, X, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error * self.activationSigmoidPrime(o)\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error * self.activationSigmoidPrime(self.z2)\n",
    "        self.W1 += X.T.dot(self.z2_delta)\n",
    "        self.W2 += self.z2.T.dot(self.o_delta)\n",
    "        \n",
    "    def trainNetwork(self, X,y):\n",
    "        o = self.feedforward(X)\n",
    "        self.backwardPropagate(X,y,o)\n",
    "    \n",
    "    def activationSigmoid(self,s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "    \n",
    "    def activationSigmoidPrime(self, s):\n",
    "        return s*(1-s)\n",
    "    \n",
    "    def saveSumSquaredLossList(self,i, error):\n",
    "        lossfile.write(str(i)+\",\"+str(error.tolist())+ '\\n')\n",
    "        \n",
    "    def saveweights(self):\n",
    "        np.savetxt(\"WeightsLayer1.txt\", self.W1, fmt = \"%s\")\n",
    "        np.savetxt(\"WeightsLayer2.txt\", self.W2, fmt = \"%s\")\n",
    "        \n",
    "    def predictOutput(self):\n",
    "        print(\"Predicted XOR output data based on trained weights: \")\n",
    "        print(\"Expected (X1-X3): \\n\" + str(xPredicted))\n",
    "        print(\"Output (Y1): \\n\" + str(self.feedforward(xPredicted)))\n",
    "        \n",
    "myNeuralNetwork = Neural_Network()\n",
    "trainingEpochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f717a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30a130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
